INFO - 10/26/19 14:39:19 - 0:00:00 - ============ Initialized logger ============
INFO - 10/26/19 14:39:19 - 0:00:00 - attention: True
                                     attention_dropout: 0
                                     back_dataset: {}
                                     back_directions: []
                                     batch_size: 32
                                     beam_size: 0
                                     clip_grad_norm: 5
                                     command: python main.py --exp_name 'test' --exp_id 'l9uerzic2x' --reload_model=./dumped/test/l9uerzic2x/checkpoint.pth --transformer 'True' --n_enc_layers '4' --max_len '100' --n_dec_layers '4' --share_enc '3' --share_dec '3' --share_lang_emb 'True' --share_encdec_emb 'True' --share_output_emb 'True' --langs 'en,fr' --n_mono '-1' --mono_dataset 'en:./data/mono/all.en.tok.60000.pth,,;fr:./data/mono/all.fr.tok.60000.pth,,' --para_dataset 'en-fr:,./data/para/dev/newstest2013-ref.XX.60000.pth,./data/para/dev/newstest2014-fren-src.XX.60000.pth' --mono_directions 'en,fr' --word_shuffle '3' --word_dropout '0.1' --word_blank '0.2' --pivo_directions 'fr-en-fr,en-fr-en' --pretrained_emb './data/mono/all.en-fr.60000.vec' --pretrained_out 'True' --lambda_xe_mono '0:1,100000:0.1,300000:0' --lambda_xe_otfd '1' --otf_num_processes '30' --otf_sync_params_every '1000' --enc_optimizer 'adam,lr=0.0001' --epoch_size '500000' --stopping_criterion 'bleu_en_fr_valid,10' --reload_enc '1' --reload_dec '1' --reload_dis '0' --exp_id "l9uerzic2x"
                                     dec_optimizer: enc_optimizer
                                     decoder_attention_heads: 8
                                     decoder_normalize_before: False
                                     dis_clip: 0
                                     dis_dropout: 0
                                     dis_hidden_dim: 128
                                     dis_input_proj: True
                                     dis_layers: 3
                                     dis_optimizer: rmsprop,lr=0.0005
                                     dis_smooth: 0
                                     dropout: 0
                                     dump_path: ./dumped/test/l9uerzic2x
                                     emb_dim: 512
                                     enc_optimizer: adam,lr=0.0001
                                     encoder_attention_heads: 8
                                     encoder_normalize_before: False
                                     epoch_size: 500000
                                     eval_only: False
                                     exp_id: l9uerzic2x
                                     exp_name: test
                                     freeze_dec_emb: False
                                     freeze_enc_emb: False
                                     group_by_size: True
                                     hidden_dim: 512
                                     id2lang: {0: 'en', 1: 'fr'}
                                     label_smoothing: 0
                                     lambda_dis: 0
                                     lambda_lm: 0
                                     lambda_xe_back: 0
                                     lambda_xe_mono: 0:1,100000:0.1,300000:0
                                     lambda_xe_otfa: 0
                                     lambda_xe_otfd: 1
                                     lambda_xe_para: 0
                                     lang2id: {'en': 0, 'fr': 1}
                                     langs: ['en', 'fr']
                                     length_penalty: 1.0
                                     lm_after: 0
                                     lm_before: 0
                                     lm_share_dec: 0
                                     lm_share_emb: False
                                     lm_share_enc: 0
                                     lm_share_proj: False
                                     lstm_proj: False
                                     max_epoch: 100000
                                     max_len: 100
                                     max_vocab: -1
                                     mono_dataset: {'en': ('./data/mono/all.en.tok.60000.pth', '', ''), 'fr': ('./data/mono/all.fr.tok.60000.pth', '', '')}
                                     mono_directions: ['en', 'fr']
                                     n_back: 0
                                     n_dec_layers: 4
                                     n_dis: 0
                                     n_enc_layers: 4
                                     n_langs: 2
                                     n_mono: -1
                                     n_para: 0
                                     otf_backprop_temperature: -1
                                     otf_num_processes: 30
                                     otf_sample: -1
                                     otf_sync_params_every: 1000
                                     otf_update_dec: True
                                     otf_update_enc: True
                                     para_dataset: {('en', 'fr'): ('', './data/para/dev/newstest2013-ref.XX.60000.pth', './data/para/dev/newstest2014-fren-src.XX.60000.pth')}
                                     para_directions: []
                                     pivo_directions: [('fr', 'en', 'fr'), ('en', 'fr', 'en')]
                                     pretrained_emb: ./data/mono/all.en-fr.60000.vec
                                     pretrained_out: True
                                     reload_dec: True
                                     reload_dis: False
                                     reload_enc: True
                                     reload_model: ./dumped/test/l9uerzic2x/checkpoint.pth
                                     relu_dropout: 0
                                     save_periodic: False
                                     seed: -1
                                     share_dec: 3
                                     share_decpro_emb: False
                                     share_enc: 3
                                     share_encdec_emb: True
                                     share_lang_emb: True
                                     share_lstm_proj: False
                                     share_output_emb: True
                                     stopping_criterion: bleu_en_fr_valid,10
                                     transformer: True
                                     transformer_ffn_emb_dim: 2048
                                     vocab: {}
                                     vocab_min_count: 0
                                     word_blank: 0.2
                                     word_dropout: 0.1
                                     word_shuffle: 3.0
INFO - 10/26/19 14:39:19 - 0:00:00 - The experiment will be stored in ./dumped/test/l9uerzic2x
                                     
INFO - 10/26/19 14:39:19 - 0:00:00 - Running command: python main.py --exp_name 'test' --exp_id 'l9uerzic2x' --reload_model=./dumped/test/l9uerzic2x/checkpoint.pth --transformer 'True' --n_enc_layers '4' --max_len '100' --n_dec_layers '4' --share_enc '3' --share_dec '3' --share_lang_emb 'True' --share_encdec_emb 'True' --share_output_emb 'True' --langs 'en,fr' --n_mono '-1' --mono_dataset 'en:./data/mono/all.en.tok.60000.pth,,;fr:./data/mono/all.fr.tok.60000.pth,,' --para_dataset 'en-fr:,./data/para/dev/newstest2013-ref.XX.60000.pth,./data/para/dev/newstest2014-fren-src.XX.60000.pth' --mono_directions 'en,fr' --word_shuffle '3' --word_dropout '0.1' --word_blank '0.2' --pivo_directions 'fr-en-fr,en-fr-en' --pretrained_emb './data/mono/all.en-fr.60000.vec' --pretrained_out 'True' --lambda_xe_mono '0:1,100000:0.1,300000:0' --lambda_xe_otfd '1' --otf_num_processes '30' --otf_sync_params_every '1000' --enc_optimizer 'adam,lr=0.0001' --epoch_size '500000' --stopping_criterion 'bleu_en_fr_valid,10' --reload_enc '1' --reload_dec '1' --reload_dis '0' --exp_id "l9uerzic2x"
                                     
INFO - 10/26/19 14:39:19 - 0:00:00 - ============ Parallel data (en - fr)
INFO - 10/26/19 14:39:19 - 0:00:00 - Loading data from ./data/para/dev/newstest2013-ref.en.60000.pth ...
INFO - 10/26/19 14:39:19 - 0:00:00 - 69883 words (60536 unique) in 3000 sentences. 1 unknown words (1 unique).
INFO - 10/26/19 14:39:19 - 0:00:00 - Loading data from ./data/para/dev/newstest2013-ref.fr.60000.pth ...
INFO - 10/26/19 14:39:19 - 0:00:00 - 80006 words (60536 unique) in 3000 sentences. 9 unknown words (6 unique).
INFO - 10/26/19 14:39:19 - 0:00:00 - Removed 0 empty sentences.
INFO - 10/26/19 14:39:19 - 0:00:00 - Removed 7 too long sentences.
INFO - 10/26/19 14:39:19 - 0:00:00 - Loading data from ./data/para/dev/newstest2014-fren-src.en.60000.pth ...
INFO - 10/26/19 14:39:19 - 0:00:00 - 76331 words (60536 unique) in 3003 sentences. 0 unknown words (0 unique).
INFO - 10/26/19 14:39:19 - 0:00:00 - Loading data from ./data/para/dev/newstest2014-fren-src.fr.60000.pth ...
INFO - 10/26/19 14:39:20 - 0:00:00 - 86849 words (60536 unique) in 3003 sentences. 0 unknown words (0 unique).
INFO - 10/26/19 14:39:20 - 0:00:00 - Removed 0 empty sentences.


INFO - 10/26/19 14:39:20 - 0:00:00 - ============ Monolingual data (en)
INFO - 10/26/19 14:39:20 - 0:00:00 - Loading data from ./data/mono/all.en.tok.60000.pth ...
INFO - 10/26/19 14:39:50 - 0:00:31 - 257569613 words (60536 unique) in 10000000 sentences. 0 unknown words (0 unique).
INFO - 10/26/19 14:39:56 - 0:00:37 - Removed 8 empty sentences.
INFO - 10/26/19 14:39:58 - 0:00:39 - Removed 23614 too long sentences.
INFO - 10/26/19 14:39:58 - 0:00:39 - ============ Monolingual data (fr)
INFO - 10/26/19 14:39:58 - 0:00:39 - Loading data from ./data/mono/all.fr.tok.60000.pth ...
INFO - 10/26/19 14:40:27 - 0:01:07 - 264624069 words (60536 unique) in 10000000 sentences. 0 unknown words (0 unique).
INFO - 10/26/19 14:40:33 - 0:01:14 - Removed 0 empty sentences.
INFO - 10/26/19 14:40:35 - 0:01:15 - Removed 30295 too long sentences.

INFO - 10/26/19 14:40:35 - 0:01:16 - ============ Data summary
INFO - 10/26/19 14:40:35 - 0:01:16 - Parallel data      - valid -   en ->   fr:      2993
INFO - 10/26/19 14:40:35 - 0:01:16 - Parallel data      -  test -   en ->   fr:      3003
INFO - 10/26/19 14:40:35 - 0:01:16 - Monolingual data   - train -           en:   9976378
INFO - 10/26/19 14:40:35 - 0:01:16 - Monolingual data   - valid -           en:         0
INFO - 10/26/19 14:40:35 - 0:01:16 - Monolingual data   -  test -           en:         0
INFO - 10/26/19 14:40:35 - 0:01:16 - Monolingual data   - train -           fr:   9969705
INFO - 10/26/19 14:40:35 - 0:01:16 - Monolingual data   - valid -           fr:         0
INFO - 10/26/19 14:40:35 - 0:01:16 - Monolingual data   -  test -           fr:         0

INFO - 10/26/19 14:40:35 - 0:01:16 - ============ Building transformer attention model - Encoder ...
INFO - 10/26/19 14:40:35 - 0:01:16 - Sharing encoder input embeddings
INFO - 10/26/19 14:40:36 - 0:01:17 - Sharing encoder transformer parameters for layer 1
INFO - 10/26/19 14:40:36 - 0:01:17 - Sharing encoder transformer parameters for layer 2
INFO - 10/26/19 14:40:36 - 0:01:17 - Sharing encoder transformer parameters for layer 3

INFO - 10/26/19 14:40:36 - 0:01:17 - ============ Building transformer attention model - Decoder ...
INFO - 10/26/19 14:40:36 - 0:01:17 - Sharing encoder and decoder input embeddings
INFO - 10/26/19 14:40:36 - 0:01:17 - Sharing decoder transformer parameters for layer 0
INFO - 10/26/19 14:40:36 - 0:01:17 - Sharing decoder transformer parameters for layer 1
INFO - 10/26/19 14:40:36 - 0:01:17 - Sharing decoder transformer parameters for layer 2
INFO - 10/26/19 14:40:37 - 0:01:18 - Sharing decoder projection matrices

/home/kmarc/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='elementwise_mean' instead.
  warnings.warn(warning.format(ret))
INFO - 10/26/19 14:40:47 - 0:01:28 - Reloading embeddings from ./data/mono/all.en-fr.60000.vec ...
INFO - 10/26/19 14:40:56 - 0:01:36 - Reloaded 60523 embeddings.
INFO - 10/26/19 14:40:59 - 0:01:40 - Initialized 60523 / 60536 word embeddings for "en" (including 0 after lowercasing).
INFO - 10/26/19 14:40:59 - 0:01:40 - Initialized 60523 / 60536 word embeddings for "fr" (including 0 after lowercasing).
INFO - 10/26/19 14:40:59 - 0:01:40 - Reloading model from ./dumped/test/l9uerzic2x/checkpoint.pth ...
Traceback (most recent call last):
  File "main.py", line 356, in <module>
    main(params)
  File "main.py", line 242, in main
    encoder, decoder, discriminator, lm = build_mt_model(params, data)
  File "/export/c03/kmarc/unsup/UnsupervisedMT/NMT/src/model/__init__.py", line 98, in build_mt_model
    return build_attention_model(params, data, cuda=cuda)
  File "/export/c03/kmarc/unsup/UnsupervisedMT/NMT/src/model/attention.py", line 819, in build_attention_model
    reloaded = torch.load(params.reload_model)
  File "/home/kmarc/anaconda3/lib/python3.6/site-packages/torch/serialization.py", line 358, in load
    return _load(f, map_location, pickle_module)
  File "/home/kmarc/anaconda3/lib/python3.6/site-packages/torch/serialization.py", line 542, in _load
    result = unpickler.load()
EOFError: Ran out of input
